\chapter{Functionality of the VO Pipeline}
The monocular visual odometry (VO) pipeline can be initialized by running the file main.m. Its functionality is summarized in the following: The loading of the data set, the bootstrapping of initial key points and processing of subsequent frames. Finally, multiple views are corrected using bundle adjustment methods. If the ground truth is given, a final alignment (achieved through scaling, rotation and translation) can be performed to judge the deviation from the reference. The last two points are described further in chapter 3.  

\section{Data Set and Parameter Settings}
Before running, three parameters can be set in 'main.m' to choose the data set and whether or not bundle adjustment and/or trajectory alignment to the ground truth should be used. Bundle adjustment and trajectory alignment are controlled through the boolean variables \emph{align\_to\_ground\_truth} and \emph{bundle\_adjustment}. The data set can be selected through the integer variable \emph{ds}.

\section{Bootstrapping}
To initialize the pipeline, an initial point cloud must be triangulated between two key frames (frame 1 and 3) and the respective camera homographies must be found. Using the Harris corner detector, key points are extracted from both images and matched (using the SSD of the respective descriptor patches). In the following step, the camera homography of frame 3 is estimated by calculating the essential matrix (since K is known) using the \emph{eight point algorithm}. To arrive at a robust estimate, RANSAC is performed with a reprojection error tolerance of ?? and 1200 iterations. The resulting inliers are then used to calculate the final landmarks and pose.      

\section{Frame Processing}
As subsequent frames are processed in a Markovian fashion, meaning that information from the previous frame is sufficient to compute all necessary variables of the subsequent frame. \par
When processing a new frame, first key points (matched with landmarks) are tracked from the previous image to the next image using the MATLAB implementation of a KLT tracker [ref]. Due to the large displacement of key points across images 3 pyramidal levels and a patch size of 31 x 31 pixels are used. \par
In a second step the new camera homography is computed using the new 2D-3D correspondences from the tracked key points. This can be computed efficiently using the MATLAB function \emph{estimateWorldCameraPose}. This function uses the P3P algorithm in combination with the M-estimator sample consensus (MSAC) to remove outliers. Using only three points allows few iterations to achieve high confidence (??\%). Non-tracked and outlier key points are removed with their corresponding landmarks.\par
Next new landmarks are triangulated from candidate key points which were tracked over several frames. Triangulation is performed between the track end and start. This means that every track starting postition with its corresponding homography are saved. New landmarks are triangulated asynchronously and only if the angle between the bearing vectors at the track start and end exceeds ??. Candidate tracks are removed if they cannot be tracked and landmarks are removed if their reprojection error exceeds ?? pixels or if they are triangulated behind the camera.\par
This candidate loss through tracking and triangulation means that new candidate keypoints must be added continuously. ?? new candidate keypoints are extracted from each frame using a Harris corner detector. To achieve a more robust behavior, Harris corner extraction is suppressed in certain areas of the image (such as right next to an existing candidate keypoint).
